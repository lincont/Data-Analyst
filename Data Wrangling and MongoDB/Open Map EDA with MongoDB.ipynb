{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling and Analysis with MongoDB\n",
    "### OpenStreetMap Project\n",
    "##### Tania Lincoln 08/20/2017\n",
    "\n",
    "### Summary\n",
    "This is preliminary investigation of the Northwest Austin custom map area.  The objective of this exercise is to clean up a portion of an open map source xml data set of 50 MB or more, format it into json, and load it into MongoDB so it can be further analyzed.  MongoDB is an opensource, no sql, document database.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "Import some common libraries and use common abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import important libraries\n",
    "import os\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Current Environment Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 2.7.13 |Anaconda 4.3.1 (64-bit)| (default, Dec 19 2016, 13:29:36) [MSC v.1500 64 bit (AMD64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#It's a good practice to display the environment information\n",
    "# print environment variables, so others can see what we are using\n",
    "print(\"python \" + sys.version)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripts Used for Wranging\n",
    "##### 1_create_sample_osm.py\n",
    "This script is executed first to create a smaller osm file from the original one.  I changed the k value so I could get different data in the sample file.\n",
    "##### 2a_audit_osm.py\n",
    "The audit script was used to learn more about the data.  I redirected an output to a file.  When I would learn more about a portion of the data, I'd make changes to the audit script and re-execute it.\n",
    "##### 3a_clean_osm.py\n",
    "This script re-shape the data into a json document so it could be loaded into mongoDB.  I chose to data wrangle roads, names, state, and phone numbers.  Because many names were actually streets, I fixed the street abbreviations similar to how address streets were fixed.  State was made into abbreviations and capatalized.  Phone numbers were standardized.  I grouped all road related tags into one subdocument and created another section with in for lane information.  gnis and tiger data was put into a sub-document, so I could talk about it more in the conclusion.  I took starter code for the address changes and refactored it, so it could be used for other data cleansing efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Files and Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert bytes to other formats to make it more easy to read  \n",
    "# Taken from: http://code.activestate.com/recipes/577081-humanized-representation-of-a-number-of-bytes/\n",
    "def humanize_bytes(bytes, precision=1):\n",
    "    \"\"\"\n",
    "    Return a humanized string representation of a number of bytes.\n",
    "    >>> humanize_bytes(1)\n",
    "    '1 byte'\n",
    "    >>> humanize_bytes(1024)\n",
    "    '1.0 kB'\n",
    "    >>> humanize_bytes(1024*123)\n",
    "    '123.0 kB'\n",
    "    >>> humanize_bytes(1024*12342)\n",
    "    '12.1 MB'\n",
    "    >>> humanize_bytes(1024*12342,2)\n",
    "    '12.05 MB'\n",
    "    >>> humanize_bytes(1024*1234,2)\n",
    "    '1.21 MB'\n",
    "    >>> humanize_bytes(1024*1234*1111,2)\n",
    "    '1.31 GB'\n",
    "    >>> humanize_bytes(1024*1234*1111,1)\n",
    "    '1.3 GB'\n",
    "    \"\"\"\n",
    "    abbrevs = (\n",
    "        (1<<50L, 'PB'),\n",
    "        (1<<40L, 'TB'),\n",
    "        (1<<30L, 'GB'),\n",
    "        (1<<20L, 'MB'),\n",
    "        (1<<10L, 'kB'),\n",
    "        (1, 'bytes')\n",
    "    )\n",
    "    if bytes == 1:\n",
    "        return '1 byte'\n",
    "    for factor, suffix in abbrevs:\n",
    "        if bytes >= factor:\n",
    "            break\n",
    "    return '%.*f %s' % (precision, bytes / factor, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NW_Austin.osm is 268.0 MB\n",
      "NW_Austin.osm.json is 547.0 MB\n"
     ]
    }
   ],
   "source": [
    "# print out the filesizes\n",
    "filesizeXML = os.path.getsize('NW_Austin.osm')\n",
    "filesizeJSON = os.path.getsize('NW_Austin.osm.json')\n",
    "\n",
    "print \"NW_Austin.osm is \" + humanize_bytes(filesizeXML, precision=1)\n",
    "print \"NW_Austin.osm.json is \" + humanize_bytes(filesizeJSON, precision=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- Data was loaded by using the bulk import command, using the following steps:\n",
    "- Make sure that Mongod, the database service, is turned on\n",
    "- From the command line, navigate to the MongoDB bin directory\n",
    "- To make the command easier to create, copy the json file to the bin directory\n",
    "- Execute the bulk import command\n",
    "    - $> mongoimport -d openMap -c nwAust --file NW_Austin.osm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data (Basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to MongoDB\n",
    "def get_db():\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('mongodb://127.0.0.1:27017')\n",
    "    db = client.openMap\n",
    "    return db\n",
    "\n",
    "# create the key data objects we'll need to analysis\n",
    "db = get_db()\n",
    "collection = db.nwAustin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an generic aggregation function\n",
    "def aggregate_collection(collection, pipeline):\n",
    "    return [doc for doc in collection.aggregate(pipeline)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Some Examples of Documents in the Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('599a037b4bdb172147b55dd4'),\n",
      " u'created': {u'changeset': u'8497118',\n",
      "              u'timestamp': u'2011-06-20T18:36:15Z',\n",
      "              u'uid': u'388279',\n",
      "              u'user': u'Tylan',\n",
      "              u'version': u'15'},\n",
      " u'id': u'26546004',\n",
      " u'pos': [u'-97.7972587', u'30.4695355'],\n",
      " u'type': u'node'}\n"
     ]
    }
   ],
   "source": [
    "docs = collection.find().limit(1)\n",
    "for doc in docs:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Road Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('599a037b4bdb172147b55dd7'),\n",
      " u'created': {u'changeset': u'13420621',\n",
      "              u'timestamp': u'2012-10-09T01:08:42Z',\n",
      "              u'uid': u'119881',\n",
      "              u'user': u'claysmalley',\n",
      "              u'version': u'28'},\n",
      " u'id': u'26546008',\n",
      " u'pos': [u'-97.7966751', u'30.469115'],\n",
      " u'road': {u'highway': u'traffic signals'},\n",
      " u'type': u'node'}\n"
     ]
    }
   ],
   "source": [
    "docs = collection.find({'road':{'$exists' :1}}).limit(1)\n",
    "for doc in docs:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amentity Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('599a037c4bdb172147b5f601'),\n",
      " u'amenity': u'fuel',\n",
      " u'created': {u'changeset': u'21599243',\n",
      "              u'timestamp': u'2014-04-10T03:02:34Z',\n",
      "              u'uid': u'703517',\n",
      "              u'user': u'Iowa Kid',\n",
      "              u'version': u'3'},\n",
      " u'id': u'340469022',\n",
      " u'name': u'Exxon',\n",
      " u'pos': [u'-97.7417023', u'30.4435595'],\n",
      " u'type': u'node'}\n"
     ]
    }
   ],
   "source": [
    "docs = collection.find({'amenity':{'$exists' :1}}).limit(1)\n",
    "for doc in docs:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Docment (Tiger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('599a03a04bdb172147c8ebea'),\n",
      " u'created': {u'changeset': u'44631401',\n",
      "              u'timestamp': u'2016-12-23T19:14:23Z',\n",
      "              u'uid': u'3747719',\n",
      "              u'user': u'cameron398',\n",
      "              u'version': u'54'},\n",
      " u'id': u'4531227',\n",
      " u'name': u'Ranch Road 620',\n",
      " u'node_ref': [u'28110282',\n",
      "               u'1332549604',\n",
      "               u'2081247373',\n",
      "               u'2234484687',\n",
      "               u'2081247421',\n",
      "               u'2234484705',\n",
      "               u'4569243745',\n",
      "               u'320892904',\n",
      "               u'4346022134',\n",
      "               u'28110282',\n",
      "               u'1332549604',\n",
      "               u'2081247373',\n",
      "               u'2234484687',\n",
      "               u'2081247421',\n",
      "               u'2234484705',\n",
      "               u'4569243745',\n",
      "               u'320892904',\n",
      "               u'4346022134',\n",
      "               u'28110282',\n",
      "               u'1332549604',\n",
      "               u'2081247373',\n",
      "               u'2234484687',\n",
      "               u'2081247421',\n",
      "               u'2234484705',\n",
      "               u'4569243745',\n",
      "               u'320892904',\n",
      "               u'4346022134',\n",
      "               u'28110282',\n",
      "               u'1332549604',\n",
      "               u'2081247373',\n",
      "               u'2234484687',\n",
      "               u'2081247421',\n",
      "               u'2234484705',\n",
      "               u'4569243745',\n",
      "               u'320892904',\n",
      "               u'4346022134',\n",
      "               u'28110282',\n",
      "               u'1332549604',\n",
      "               u'2081247373',\n",
      "               u'2234484687',\n",
      "               u'2081247421',\n",
      "               u'2234484705',\n",
      "               u'4569243745',\n",
      "               u'320892904',\n",
      "               u'4346022134',\n",
      "               u'28110282',\n",
      "               u'1332549604',\n",
      "               u'2081247373',\n",
      "               u'2234484687',\n",
      "               u'2081247421',\n",
      "               u'2234484705',\n",
      "               u'4569243745',\n",
      "               u'320892904',\n",
      "               u'4346022134'],\n",
      " u'old_ref': u'FM 620',\n",
      " u'ref': u'TX 45;RM 620',\n",
      " u'road': {u'highway': u'primary'},\n",
      " u'tiger': {u'cfcc': u'A41',\n",
      "            u'county': u'Williamson, TX',\n",
      "            u'name_direction_suffix': u'N',\n",
      "            u'reviewed': u'no',\n",
      "            u'zip_right': u'78681'},\n",
      " u'tiger:zip_left_1': u'78681',\n",
      " u'type': u'way'}\n"
     ]
    }
   ],
   "source": [
    "docs = collection.find({'tiger':{'$exists' :1}}).limit(1)\n",
    "for doc in docs:\n",
    "    pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of documents in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1402041 documents in the collection\n"
     ]
    }
   ],
   "source": [
    "count = collection.find().count()\n",
    "print \"There are \" + str(count) + \" documents in the collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1280258 nodes\n"
     ]
    }
   ],
   "source": [
    "count = collection.find({'type':'node'}).count()\n",
    "print \"There are \" + str(count) + \" nodes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 121782 ways\n"
     ]
    }
   ],
   "source": [
    "count = collection.find({'type':'way'}).count()\n",
    "print \"There are \" + str(count) + \" ways\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What other types are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'node', u'way', u'multipolygon']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(db.nwAustin.distinct('type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of multipolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 multipolygons\n"
     ]
    }
   ],
   "source": [
    "count = collection.find({'type':'multipolygon'}).count()\n",
    "print \"There are \" + str(count) + \" multipolygons\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distinct User Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users and User ID have the same count \n",
      "\n",
      "There are 478 distinct users\n"
     ]
    }
   ],
   "source": [
    "count_uid = len(collection.distinct('created.uid'))\n",
    "count_user = len(collection.distinct('created.user'))\n",
    "if count_uid == count_user:\n",
    "    print \"Users and User ID have the same count \\n\"\n",
    "    print \"There are \" + str(count_uid) + \" distinct users\"\n",
    "else:\n",
    "    print \"User and User IDs have a different count\\n\"\n",
    "    print \"There are \" + str(count_uid) + \" distinct user IDs and \" + str(count_user) + \" user names\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data (more complex questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question:  Who are the top 5 contributers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'ccjjmartin_atxbuildings', u'count': 581431},\n",
      " {u'_id': u'ccjjmartin__atxbuildings', u'count': 424789},\n",
      " {u'_id': u'patisilva_atxbuildings', u'count': 89956},\n",
      " {u'_id': u'kkt_atxbuildings', u'count': 65767},\n",
      " {u'_id': u'wilsaj_atxbuildings', u'count': 64101},\n",
      " {u'_id': u'richlv', u'count': 22007},\n",
      " {u'_id': u'woodpeck_fixbot', u'count': 18010},\n",
      " {u'_id': u'HJD', u'count': 16562},\n",
      " {u'_id': u'ELadner', u'count': 12631},\n",
      " {u'_id': u'lyzidiamond_atxbuildings', u'count': 10902}]\n"
     ]
    }
   ],
   "source": [
    "group = {\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}\n",
    "sort = {\"$sort\":{\"count\":-1}}\n",
    "limit = {\"$limit\":10}\n",
    "pipeline = [group, sort, limit]\n",
    "pprint.pprint(aggregate_collection(collection, pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ccjjmartin is the highest contributor.  This persons login is split amongst two names and two ids.  Biggest contributors overall come from atxbuildings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question:  When were the last few contribution made?  How many changes were submitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'2017-08-05T07:15:33Z', u'count': 1},\n",
      " {u'_id': u'2017-08-04T15:59:56Z', u'count': 1},\n",
      " {u'_id': u'2017-08-04T06:21:02Z', u'count': 1},\n",
      " {u'_id': u'2017-08-02T21:32:12Z', u'count': 10},\n",
      " {u'_id': u'2017-08-02T21:32:11Z', u'count': 7},\n",
      " {u'_id': u'2017-08-02T21:32:10Z', u'count': 22},\n",
      " {u'_id': u'2017-08-02T21:32:09Z', u'count': 40},\n",
      " {u'_id': u'2017-08-02T21:32:08Z', u'count': 9},\n",
      " {u'_id': u'2017-08-02T21:32:07Z', u'count': 13},\n",
      " {u'_id': u'2017-08-02T21:32:06Z', u'count': 12}]\n"
     ]
    }
   ],
   "source": [
    "group = {\"$group\":{\"_id\":\"$created.timestamp\", \"count\":{\"$sum\":1}}}\n",
    "sort = {\"$sort\":{\"_id\":-1}}\n",
    "limit = {\"$limit\":10}\n",
    "pipeline = [group, sort, limit]\n",
    "pprint.pprint(aggregate_collection(collection, pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes have been recently made!  The date was difficult to handle.  I would have liked to just have dates instead of timestamps to see what the trending over time has been.  Austin has a lot of new construction and changes, I wanted to see if this was reflected in the inserted dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question:  What amenities are in the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'parking', u'count': 439},\n",
      " {u'_id': u'restaurant', u'count': 194},\n",
      " {u'_id': u'fast food', u'count': 149},\n",
      " {u'_id': u'school', u'count': 87},\n",
      " {u'_id': u'fuel', u'count': 81},\n",
      " {u'_id': u'place of worship', u'count': 67},\n",
      " {u'_id': u'bank', u'count': 44},\n",
      " {u'_id': u'waste basket', u'count': 42},\n",
      " {u'_id': u'bench', u'count': 33},\n",
      " {u'_id': u'cafe', u'count': 29}]\n"
     ]
    }
   ],
   "source": [
    "match = {\"$match\":{\"amenity\":{\"$exists\":1}}}\n",
    "group = {\"$group\":{\"_id\":\"$amenity\", \"count\":{\"$sum\":1}}}\n",
    "sort = {\"$sort\":{\"count\":-1}}\n",
    "limit = {\"$limit\":10}\n",
    "pipeline = [match, group, sort, limit]\n",
    "pprint.pprint(aggregate_collection(collection, pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, lots of parking in NW Austin.  Other than parking being first, the top half doesn't surprise me.  NW Austin is very suburban, lots of infrastructure for families and homes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question:  What type of fast food and resturants does NW Austin like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': None, u'count': 215},\n",
      " {u'_id': u'burger', u'count': 22},\n",
      " {u'_id': u'mexican', u'count': 21},\n",
      " {u'_id': u'sandwich', u'count': 14},\n",
      " {u'_id': u'pizza', u'count': 12},\n",
      " {u'_id': u'chinese', u'count': 9},\n",
      " {u'_id': u'american', u'count': 8},\n",
      " {u'_id': u'italian', u'count': 8},\n",
      " {u'_id': u'sushi', u'count': 8},\n",
      " {u'_id': u'coffee shop', u'count': 7}]\n"
     ]
    }
   ],
   "source": [
    "match = {\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\": {\"$in\" :[\"fast food\", \"restaurant\", \"cafe\"]}}}\n",
    "group = {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}}\n",
    "sort = {\"$sort\":{\"count\":-1}}\n",
    "limit = {\"$limit\":10}\n",
    "pipeline = [match, group, sort, limit]\n",
    "pprint.pprint(aggregate_collection(collection, pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately a lot of the resturants are not classified.  Because it's Austin, I would suspect a lot of Mexican and Tex-Mex resturants - we love our tacos!  However, since it's NW Austin, I would have suspected more cuisines from asian countries too.  This list looks fairly typical with burgers, sandwhiches, and pizza in the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question:  What type of road ways are there?  Do cars rule or is there room for pedestrians and bikes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': None, u'count': 17108},\n",
      " {u'_id': u'residential', u'count': 4493},\n",
      " {u'_id': u'footway', u'count': 376},\n",
      " {u'_id': u'unclassified', u'count': 108},\n",
      " {u'_id': u'path', u'count': 79},\n",
      " {u'_id': u'cycleway', u'count': 20},\n",
      " {u'_id': [u'cycleway'], u'count': 12},\n",
      " {u'_id': u'pedestrian', u'count': 3}]\n"
     ]
    }
   ],
   "source": [
    "match = {\"$match\":{\"road\":{\"$exists\":1}}}\n",
    "project = {\"$project\":{\"road_type\":[\"$road.mode\", \"$road.highway\"]}}\n",
    "unwind = {\"$unwind\": \"$road_type\"}\n",
    "group = {\"$group\":{\"_id\":\"$road_type\", \"count\":{\"$sum\":1}}}\n",
    "match2 = {\"$match\":{\"_id\":{\"$in\":[None, \"footway\", \"path\", \"[sidewalk]\", \n",
    "                                  \"residential\", \"unclassified\", \"cycleway\", \"[cycleway]\", \"pedestrian\"]}}}\n",
    "sort =  {\"$sort\":{\"count\":-1}}\n",
    "limit = {\"$limit\":100}\n",
    "pipeline = [match, project, unwind, group, match2, sort, limit]\n",
    "pprint.pprint(aggregate_collection(collection, pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are numerous places for other modes of transportation, however roadways for cars dominate.  There are also very few dedicated cycleways.  However, many residential streets would serve all purposes.  This is pretty tricky to investigate, the data would need much more cleansing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had a really hard time parsing dates using the aggregation pipeline.  They are formatted as follows:  '2017-08-05T07:15:33Z'.  Given this, I would have transformed the data before loading it into mongoDB.  I wanted to investigate whether changes have spiked in the last few years because of growth.  \n",
    "\n",
    "The tiger and gnis data seemed really subdivided and repetitive to other sections.  For example, name would often have a street address when a node was describing a road.  The same name would be represented in 3 sections for the tiger data.  I was going to ignore all of it, but decided to keep it for my conclusion.  I created a sub-document for each.\n",
    "\n",
    "Here is an example of how Swan Drive appears in the name and how it appears in the tiger parts.\n",
    "\n",
    "u'name': u'Swan Drive',\n",
    "  u'tiger': {u'cfcc': u'A41',\n",
    "             u'county': u'Travis, TX',\n",
    "             u'name_base': u'Swan',\n",
    "             u'name_type': u'Dr',\n",
    "             u'reviewed': u'no',\n",
    "             u'zip_left': u'78750',\n",
    "             u'zip_right': u'78750'},\n",
    "            \n",
    "Another issue with the tiger data was the zip codes.  There was a zip_left and a zip_right. In my data investigation, there seemed no difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other ideas about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### API integration with yelp or creating our own map-yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use activity sites APIs like yelp or opentable to audit and source data. It's more upto date than the yellow pages and driven by a community of active users.  Ratings and Closed statuses could help drive relevance and cleanup.\n",
    "\n",
    "Like there are trusted reviews on yelp.  We could also add ratings to the quality of open map data added by a user and have a leaderboard for how manu submission or fixes they've made.\n",
    "\n",
    "An exteral app, like yelp, could be created for other map features.  Where users could tag map features features like the best rush hour route, the hilliest road run, best scenic outlook, or my favorite motorcycle drive.  We can use this personalization to create a community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is still 1 BlockBuster.  They all closed in 2008-ish.\n"
     ]
    }
   ],
   "source": [
    "count = collection.find({'name':'Block Buster'}).count()\n",
    "print \"There is still \" + str(count) + \" BlockBuster.  They all closed in 2008-ish.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelpers Report it as being closed.\n",
    "- https://www.yelp.com/biz/blockbuster-video-austin-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are newer resturants in the area, which have not been included in openMaps yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some new places that haven't been included into OpenMaps yet.\n",
      "\n",
      "Baretto is missing\n",
      "Kanji Ramen is missing\n",
      "Pour House is missing\n"
     ]
    }
   ],
   "source": [
    "print \"Here are some new places that haven't been included into OpenMaps yet.\\n\"\n",
    "\n",
    "count = collection.find({\"name\" : {\"$regex\" : \".*[b|B]aretto.*\"}}).count()\n",
    "if count == 0:\n",
    "    print \"Baretto is missing\"\n",
    "else:\n",
    "    print \"Baretto is included\"\n",
    "    \n",
    "count = collection.find({\"name\" : {\"$regex\" : \".*[k|K]anji.*\"}}).count()\n",
    "if count == 0:\n",
    "    print \"Kanji Ramen is missing\"\n",
    "else:\n",
    "    print \"Kanji Ramen is included\"\n",
    "    \n",
    "count = collection.find({\"name\" : {\"$regex\" : \".*[p|P]our.*\"}}).count()\n",
    "if count == 0:\n",
    "    print \"Pour House is missing\"\n",
    "else:\n",
    "    print \"Pour House is included\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.yelp.com/biz/baretto-austin\n",
    "- https://www.yelp.com/biz/kanji-ramen-austin\n",
    "- https://www.yelp.com/biz/pour-house-pints-and-pies-austin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Possible Challenges with integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for this to work users really need to favor apps like yelp.  Tying our success to yelps success could cause reworkd down the road.  Yelp really only has businesses and data about businesses.  We'd be missing opportunities for better data in areas related to roadways or geographic features.\n",
    "\n",
    "To creat an app similar to yelp would be undertaking a lot of new responsibilities.  Only good community engagement will make it successful.  Because I could tag a route and others could tag similar routes, we'd have the potential for duplicate data or worse having to make a choice for which data is most correct or should be included.  I think we'd run into a similar situation seen with the tiger and gnis data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://stackoverflow.com/questions/20796714/how-do-i-start-mongo-db-from-windows\n",
    "- http://wiki.openstreetmap.org/wiki/USGS_GNIS\n",
    "- http://wiki.openstreetmap.org/wiki/TIGER_to_OSM_Attribute_Map\n",
    "- https://docs.google.com/document/d/1F0Vs14oNEs2idFJR3C_OPxwS6L0HPliOii-QpbmrMo4/pub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Template Version History\n",
    "1.0, 06/30/2017, Created"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
